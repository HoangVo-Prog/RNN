{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoangVo-Prog/simple-RNN/blob/main/1_il_TextVectorization_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d18b44e-52dd-42ff-9827-6442a7f11550",
      "metadata": {
        "id": "2d18b44e-52dd-42ff-9827-6442a7f11550"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7396594c",
      "metadata": {
        "id": "7396594c",
        "outputId": "701a6383-179e-4e9d-a002-ee72c5cf4b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torchtext) (2.32.2)\n",
            "Requirement already satisfied: torch>=2.3.0 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torchtext) (2.3.0)\n",
            "Requirement already satisfied: numpy in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (4.11.0)\n",
            "Requirement already satisfied: sympy in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from requests->torchtext) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from requests->torchtext) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from requests->torchtext) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Downloading torchtext-0.18.0-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069c60c4-ccb8-403c-b16a-7266f9a1ff6a",
      "metadata": {
        "id": "069c60c4-ccb8-403c-b16a-7266f9a1ff6a",
        "outputId": "0f5ffdf3-fcff-404c-8a5d-710b34d109da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['we', 'are', 'learning', 'ai']\n",
            "['ai', 'is', 'a', 'cs', 'topic']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "sample1 = 'We are learning AI'\n",
        "sample2 = 'AI is a CS topic'\n",
        "\n",
        "# Define tokenizer function\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "sample1_tokens = tokenizer(sample1)\n",
        "sample2_tokens = tokenizer(sample2)\n",
        "\n",
        "print(sample1_tokens)\n",
        "print(sample2_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9125ed1e-9f13-408c-8f79-9bb4bdc58572",
      "metadata": {
        "id": "9125ed1e-9f13-408c-8f79-9bb4bdc58572"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "700ffe54-f581-45aa-98a3-441c1dc85b43",
      "metadata": {
        "id": "700ffe54-f581-45aa-98a3-441c1dc85b43"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "sample1 = 'We are learning AI'\n",
        "sample2 = 'AI is a CS topic'\n",
        "data = [sample1, sample2]\n",
        "\n",
        "# Create a function to yield list of tokens\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "def yield_tokens(examples):\n",
        "    for text in examples:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Create vocabulary\n",
        "vocab_size = 8\n",
        "vocab = build_vocab_from_iterator(yield_tokens(data),\n",
        "                                  max_tokens=vocab_size,\n",
        "                                  specials=[\"<unk>\",\n",
        "                                            \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e337b92e-bf41-4d10-afbe-096418095da4",
      "metadata": {
        "id": "e337b92e-bf41-4d10-afbe-096418095da4",
        "outputId": "cc370928-be81-4461-e42f-2a6e9e63fb92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'learning': 7,\n",
              " 'is': 6,\n",
              " 'are': 4,\n",
              " 'a': 3,\n",
              " 'cs': 5,\n",
              " 'ai': 2,\n",
              " '<pad>': 1,\n",
              " '<unk>': 0}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab.get_stoi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f3ac4d-3a85-4d56-85ca-e8ee9c969a91",
      "metadata": {
        "id": "88f3ac4d-3a85-4d56-85ca-e8ee9c969a91"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9f1d59f-c4b5-42d1-bb56-54b51ea50c33",
      "metadata": {
        "id": "b9f1d59f-c4b5-42d1-bb56-54b51ea50c33",
        "outputId": "36cad79f-17e5-4621-fe91-cc5f7a8b1595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['we', 'are', 'learning', 'ai']\n",
            "[0, 4, 7, 2]\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer(sample1)\n",
        "print(tokens)\n",
        "\n",
        "sample1_tokens = [vocab[token] for token in tokens]\n",
        "print(sample1_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "495dad80-c3fb-4635-9d67-c7897c601c06",
      "metadata": {
        "id": "495dad80-c3fb-4635-9d67-c7897c601c06",
        "outputId": "feaa2154-2d0c-4632-96f7-c184faba7271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ai', 'is', 'a', 'cs', 'topic']\n",
            "[2, 6, 3, 5, 0]\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer(sample2)\n",
        "print(tokens)\n",
        "\n",
        "sample2_tokens = [vocab[token] for token in tokens]\n",
        "print(sample2_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c175a8-1309-4e38-88a5-b678318514b4",
      "metadata": {
        "id": "27c175a8-1309-4e38-88a5-b678318514b4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ae1cfe-b2a0-44d1-99ce-f537a74ab151",
      "metadata": {
        "id": "10ae1cfe-b2a0-44d1-99ce-f537a74ab151",
        "outputId": "55d35b21-3194-4a96-daa0-4483ee40645c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorized Sample 1: tensor([0, 4, 7, 2, 1])\n",
            "Vectorized Sample 2: tensor([2, 6, 3, 5, 0])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def vectorize(text, vocab, seq_len):\n",
        "    tokens = tokenizer(text)\n",
        "    tokens = [vocab[token] for token in tokens]\n",
        "\n",
        "    num_pads = sequence_length - len(tokens)\n",
        "    tokens = tokens[:sequence_length] + [vocab[\"<pad>\"]]*num_pads\n",
        "\n",
        "    return torch.tensor(tokens, dtype=torch.long)\n",
        "\n",
        "# Vectorize the samples\n",
        "sequence_length = 5\n",
        "vectorized_sample1 = vectorize(sample1, vocab,\n",
        "                               sequence_length)\n",
        "vectorized_sample2 = vectorize(sample2, vocab,\n",
        "                               sequence_length)\n",
        "\n",
        "print(\"Vectorized Sample 1:\", vectorized_sample1)\n",
        "print(\"Vectorized Sample 2:\", vectorized_sample2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "897b7f8e-1118-45e5-9b8d-6c31a7fe4113",
      "metadata": {
        "id": "897b7f8e-1118-45e5-9b8d-6c31a7fe4113",
        "outputId": "41167da0-1dce-4c91-9c31-cda7eea8be24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 0, 0, 5, 6])\n"
          ]
        }
      ],
      "source": [
        "sample3 = 'AI topic in CS is difficult'\n",
        "vectorized_sample3 = vectorize(sample3, vocab,\n",
        "                               sequence_length)\n",
        "print(vectorized_sample3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a026fa8-8860-49e1-a621-18596279af5d",
      "metadata": {
        "id": "2a026fa8-8860-49e1-a621-18596279af5d"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fa0ebb-c8e0-4ef3-9ea1-bdca2c51c888",
      "metadata": {
        "id": "f7fa0ebb-c8e0-4ef3-9ea1-bdca2c51c888",
        "outputId": "0e326aa2-967a-4e04-edcc-cf8af84db437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1882,  0.5530,  1.6267,  0.7013],\n",
            "        [ 1.7840, -0.8278, -0.2701,  1.3586],\n",
            "        [ 1.0281, -1.9094,  0.3182,  0.4211],\n",
            "        [-1.3083, -0.0987,  0.7647, -0.3680],\n",
            "        [ 0.2293,  1.3255,  0.1318,  2.0501],\n",
            "        [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
            "        [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
            "        [ 0.4309, -1.3067, -0.8823,  1.5977]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = 8\n",
        "embed_dim = 4\n",
        "embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "custom_weights = torch.tensor( [[-0.1882,  0.5530,  1.6267,  0.7013],\n",
        "                                [ 1.7840, -0.8278, -0.2701,  1.3586],\n",
        "                                [ 1.0281, -1.9094,  0.3182,  0.4211],\n",
        "                                [-1.3083, -0.0987,  0.7647, -0.3680],\n",
        "                                [ 0.2293,  1.3255,  0.1318,  2.0501],\n",
        "                                [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
        "                                [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
        "                                [ 0.4309, -1.3067, -0.8823,  1.5977]]).float()\n",
        "embedding.weight = nn.Parameter(custom_weights)\n",
        "print(embedding.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a027791-dc92-4ac7-8fb7-20c68d528a93",
      "metadata": {
        "id": "3a027791-dc92-4ac7-8fb7-20c68d528a93"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "59e8091c-b48c-479e-afb4-500f25f75835",
      "metadata": {
        "id": "59e8091c-b48c-479e-afb4-500f25f75835"
      },
      "source": [
        "## Update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab9d2b8-bc27-45ff-9860-27d5eb74d2b5",
      "metadata": {
        "id": "eab9d2b8-bc27-45ff-9860-27d5eb74d2b5",
        "outputId": "7e4ba43a-8a34-49f4-c781-57b21dd6b631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1882,  0.5530,  1.6267,  0.7013],\n",
            "        [ 1.7840, -0.8278, -0.2701,  1.3586],\n",
            "        [ 1.0281, -1.9094,  0.3182,  0.4211],\n",
            "        [-1.3083, -0.0987,  0.7647, -0.3680],\n",
            "        [ 0.2293,  1.3255,  0.1318,  2.0501],\n",
            "        [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
            "        [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
            "        [ 0.4309, -1.3067, -0.8823,  1.5977]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = 8\n",
        "embed_dim = 4\n",
        "embedding = nn.Embedding(vocab_size,\n",
        "                         embed_dim)\n",
        "\n",
        "custom_weights = torch.tensor( [[-0.1882,  0.5530,  1.6267,  0.7013],\n",
        "                                [ 1.7840, -0.8278, -0.2701,  1.3586],\n",
        "                                [ 1.0281, -1.9094,  0.3182,  0.4211],\n",
        "                                [-1.3083, -0.0987,  0.7647, -0.3680],\n",
        "                                [ 0.2293,  1.3255,  0.1318,  2.0501],\n",
        "                                [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
        "                                [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
        "                                [ 0.4309, -1.3067, -0.8823,  1.5977]]).float()\n",
        "embedding.weight = nn.Parameter(custom_weights)\n",
        "print(embedding.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcffa230-ef6c-450d-a781-e9b20f727dc9",
      "metadata": {
        "id": "dcffa230-ef6c-450d-a781-e9b20f727dc9"
      },
      "outputs": [],
      "source": [
        "data = torch.tensor([0, 4, 7, 2, 1], dtype=torch.long)\n",
        "label = torch.tensor([1], dtype=torch.float)\n",
        "\n",
        "x = embedding(data)\n",
        "x = nn.Flatten(0)(x)\n",
        "x = nn.Linear(20, 1)(x)\n",
        "output = nn.Sigmoid()(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49429089-131c-414f-94a6-4a2dccd17b3d",
      "metadata": {
        "id": "49429089-131c-414f-94a6-4a2dccd17b3d",
        "outputId": "e39faed5-e929-49f9-cd63-02a2937ab51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1872,  0.5520,  1.6277,  0.7023],\n",
            "        [ 1.7850, -0.8288, -0.2711,  1.3596],\n",
            "        [ 1.0291, -1.9084,  0.3172,  0.4221],\n",
            "        [-1.3083, -0.0987,  0.7647, -0.3680],\n",
            "        [ 0.2303,  1.3265,  0.1308,  2.0511],\n",
            "        [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
            "        [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
            "        [ 0.4299, -1.3057, -0.8833,  1.5987]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "loss = nn.BCELoss()(output, label)\n",
        "optimizer = torch.optim.Adam(embedding.parameters())\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "print(embedding.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e250447-6ebf-4cf2-ae22-19c2c282be1b",
      "metadata": {
        "id": "1e250447-6ebf-4cf2-ae22-19c2c282be1b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}